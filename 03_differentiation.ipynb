{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5621feda",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "    \n",
    "## <font color='maroon'>ASTR 21100/31200</font>\n",
    "## <font color='maroon'>Computational techniques in astrophysics<br></font>\n",
    "\n",
    "## <font color='maroon'>Numerical computation of derivatives<br></font>\n",
    "</center>\n",
    "\n",
    "\n",
    "\n",
    "### Instructor: \n",
    "Andrey Kravtsov (email: <tt>kravtsov@uchicago.edu</tt>)\n",
    "Professor,<br> Department of Astronomy & Astrophysics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84a467f",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Computing derivatives numerically\n",
    "\n",
    "``*Finite differences have, in themselves, but little importance to the student of matter and ether. They are here regarded simply as a makeshift for infinitesimals; and the understanding is always that we will eventually make the differences so small that the errors due to their finite size will be less than the errors of experiment of practical working, and may therefore be disregarded. That it is possible to make them small enough without much labour is illustrated by examples given hereafter.*''\n",
    "    \n",
    "                -- Lewis Fry Richardson, 1910\n",
    "    \n",
    "    \n",
    "For some functions we can derive mathematical expression for a function derivative. For many others, such derivatives are either difficult or impossible to compute using direct mathematical derivation. In such cases it is still possible to compute approximate derivatives numerically. \n",
    "    \n",
    "Also, in practice we often deal with tabulated data. Derivatives of functions represented by such data evaluated only at certain discrete values of their argument also need to be evaluated numerically (i.e., using calculations of the kind discussed below). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70490e8e",
   "metadata": {},
   "source": [
    "### <font color='darkblue'>The basis for numerical estimates of derivatives is Taylor series expansion \n",
    "\n",
    "$$f(x) = f(x_0)+f^\\prime(x_0)\\,(x-x_0)+\\frac{1}{2}f^{\\prime\\prime}(x_0)\\,(x-x_0)^2 + \\mathcal{O}[(x-x_0)^3],$$\n",
    "\n",
    "where $f^\\prime(x_0)$ is derivative of $f(x)$ with respect to $x$ evaluated at point $x_0$, while $f^{\\prime\\prime}(x_0)$ is 2nd derivative, etc. \n",
    "    \n",
    "The term $\\mathcal{O}[(x-x_0)^3]$ is the standard shorthand for ``and terms of order 3 and higher''. If we neglect terms above certain order, we are no longer guaranteed to represent $f(x)$ exactly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2e57df",
   "metadata": {},
   "source": [
    "### <font color='darkblue'>Numerical evaluation of $f^\\prime(x)$ \n",
    "\n",
    "follows from the Taylor expansion because we can define $h = x - x_0$ and rewrite the expansion as \n",
    "    \n",
    "$$f(x_0+h) = f(x_0)+f^\\prime(x_0)\\,h + e_1\\,h^2 +  e_2\\,h^3 + \\mathcal{O}(h^4),$$\n",
    "    \n",
    "where $e_1 = f^{\\prime\\prime}(x_0)/2$, $e_2 = f^{\\prime\\prime\\prime}(x_0)/6$.\n",
    "From this we can see that \n",
    "    \n",
    "$$f^\\prime(x_0)=\\frac{f(x_0+h) - f(x_0)}{h} - e_1\\,h -  e_2\\,h^2 + \\mathcal{O}(h^3).$$\n",
    "    \n",
    "or\n",
    "    \n",
    "$$\\frac{f(x_0+h) - f(x_0)}{h} = f^\\prime(x_0) + e_1\\,h +  e_2\\,h^2 + \\mathcal{O}(h^3) = f^\\prime(x_0) + \\epsilon_{\\rm trunc}.$$\n",
    "\n",
    "As before, $\\epsilon_{\\rm trunc}$ here is *truncation error of the approximation of the derivative given by $[f(x_0+h) - f(x_0)]/h$. The first (``leading'') term of the truncation error is $e_1, h$. Due to the 1st power of $h$ in this term, it is said that this numerical estimator of the derivative is 1st order accurate. \n",
    "    \n",
    "We can construct a similar estimator by using $x = x_0 - h$ which by similar algebra gives:\n",
    "    \n",
    " $$\\frac{f(x_0) - f(x_0-h)}{h} = f^\\prime(x_0) - e_1\\,h +  e_2\\,h^2 + \\mathcal{O}(h^3).$$\n",
    "   \n",
    " \n",
    "If we sum the two estimators and divide the sum by 2 (i.e. average them) we get\n",
    "    \n",
    "$$\\frac{f(x_0+h) - f(x_0-h)}{2h} = f^\\prime(x_0) + e_2\\,h^2 + \\mathcal{O}(h^4).$$\n",
    " \n",
    "Thus, we constructed a new *numerical estimator* of $f^\\prime(x_0)$, which has leading term in the truncation error proportional to $h^2$ instead of $h$, which makes it *second order accurate*. The accuracy of this estimator will thus improve much faster with decreasing $h$, then the 1st order estimators above. In fact, this estimator is sufficiently good in most situations in practice.    \n",
    "    \n",
    "    \n",
    "You may also notice that we got rid of the term in the truncation error proportional to $h^3$ and in fact of all odd-power terms, by cancellation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56157525",
   "metadata": {},
   "source": [
    "We can in principle, improve the estimator to the 4th order by eleminating the term $e_2h^2$ by estimating derivative for $h/2$ instead of $h$ and \n",
    "\n",
    "$$4\\,\\frac{f(x_0+h/2) - f(x_0-h/2)}{2h} = 4f^\\prime(x_0) + 4e_2\\,\\frac{h}{2}^2 + \\mathcal{O}(h^4)=4f^\\prime(x_0) + e_2\\,h^2 + \\mathcal{O}(h^4)$$\n",
    "\n",
    "and subtracting the previous estimator from the above expression and dividing by 3:\n",
    "\n",
    "$$4\\,\\frac{f(x_0+h/2) - f(x_0-h/2)}{2h}-\\frac{f(x_0+h) - f(x_0-h)}{2h} = 3f^\\prime(x_0) +  \\mathcal{O}(h^4)$$\n",
    "\n",
    "or \n",
    "\n",
    "$$\\frac{4[f(x_0+h/2) - f(x_0-h/2)] - [f(x_0+h) - f(x_0-h)]}{6h} = f^\\prime(x_0) +  \\mathcal{O}(h^4)$$\n",
    "\n",
    "which is a 4th order estimator of $f^\\prime(x_0)$. We can get rid of the $h^4$ term in the truncation error in the same way to construct a 6th order scheme, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d12b65",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <font color='darkblue'>Richardson's approach to the limit \n",
    "\n",
    "The trick used above to successively eliminate leading term in the truncation error to construct successively higher order schemes was devised by physicist Lewis Fry Richardson, who studied turbulence in the atmosphere and doing numerical simulations of such turbulent flows before electronic computers existed. \n",
    "    \n",
    "Richardson wanted to devise a method which would allow to get accurate result in calculations involving derivatives while making as few calculations by hand as possible, because these would need to be done by humans. \n",
    "    \n",
    "<img size=500 src=\"http://astro.uchicago.edu/~andrey/classes/a330f17/fig/Lewis_Fry_Richardson_wiki_photo.png\"></img>\n",
    "\n",
    "<center>Lewis Fry Richardson</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d736f0aa",
   "metadata": {},
   "source": [
    "### <font color='darkblue'>Estimator of the 2nd order derivative  \n",
    "\n",
    "In general to achieve truncation error of order $n$ we will need $n+1$ or more function values. With this knowledge in mind, we can construct finite difference schemes for an arbitrary derivative order to arbitrary error order. For example, to get second derivative at $x$ to second order using function values at $x\\pm h$, we can write:\n",
    "\n",
    "\\begin{eqnarray}    \n",
    "f^{\\prime\\prime}(x) &\\approx& Af(x+h)+Bf(x)+C f(x-h) = A\\left [f(x)+h f^\\prime(x) +\\frac{h^2}{2}f^{\\prime\\prime}(x)\\right] +\\\\\\nonumber\n",
    "&&Bf(x)+C\\left [f(x)-h f^\\prime(x) +\\frac{h^2}{2}f^{\\prime\\prime}(x)\\right] = (A+B+C)f(x) + (A-C) h f^\\prime(x) + (A+C)\\frac{h^2}{2}f^{\\prime\\prime}(x).\n",
    "\\end{eqnarray}\n",
    "\n",
    "Then from the equation it follows that $A+B+C=0$, $A-C=0$ and $A+C=2/h^2$, which gives $A=C=1/h^2$ and $B=-2/h^2$, so that \n",
    "\n",
    "\\begin{equation}\n",
    "f^{\\prime\\prime}(x) = \\frac{f(x+h)-2f(x) + f(x-h)}{h^2} + \\mathcal{O}(h^2). \n",
    "\\end{equation}\n",
    "This approach is called the *method of undetermined coefficients.* \n",
    "\n",
    "It can also be used  to construct designer finite difference schemes for the ends of the interval on which $f(x)$ is tabulated. For example, we can try to derive 2nd order finite difference scheme for the second derivative on the left border of the interval $x=x_{\\rm min}$. However, repeating above for \n",
    "points $x$, $x+h$, $x+2h$ we get only a first order approximation\n",
    "\\begin{equation}\n",
    "f^{\\prime\\prime}(x) = \\frac{f(x)-2f(x+h) + f(x+2h)}{h^2} + \\mathcal{O}(h). \n",
    "\\end{equation}\n",
    "This also reflects the fact that more function evaluations are needed to maintain order for asymmetric stencils.  The second order scheme can be constructed using four points: \n",
    "\\begin{equation}\n",
    "f^{\\prime\\prime}(x) = \\frac{2f(x)-5f(x+h) + 4f(x+2h)-f(x+3h)}{h^2} + \\mathcal{O}(h^2). \n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a187765e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
