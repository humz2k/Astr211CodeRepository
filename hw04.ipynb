{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c784ad9",
   "metadata": {
    "id": "lgTo8qRPumw6"
   },
   "source": [
    "## <font color='blue'> ASTR 21100/31200</font>\n",
    "\n",
    "## <font color='blue'> Homework Assignment 4</font>\n",
    "    \n",
    "## <font color='blue'> Approximating 2D function using interpolation and regression</font>\n",
    "\n",
    "## <font color='blue'> Implementing Differential Evolution algorithm</font>\n",
    "\n",
    "## <font color='blue'> undergraduate students (35 points + 15 extra-credit)</font>\n",
    "    \n",
    "### <font color='blue'> Distributed: Friday, April 22</font>\n",
    "\n",
    "### <font color='blue'> Due: Friday, Apr 29, 9pm</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bb6536",
   "metadata": {},
   "source": [
    "import packages needed by the codes below. Run this cell first before using these codes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30db0b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# use jupyter \"magic\" command to tell it to embed plot into the notebook \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from codes.plotting import plot_prettier, plot_line_points\n",
    "\n",
    "plot_prettier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f3d6e3",
   "metadata": {},
   "source": [
    "## <font color='blue'>Exercise 1 (10 points): constructing optimal approximation for $d_L(\\Omega_{\\rm m0},\\Omega_\\Lambda)$</font>\n",
    "\n",
    "**Background.** In the past two weeks you learned how to compute of the luminosity distance $d_L(z,H_0,\\Omega_{\\rm m0},\\Omega_\\Lambda)$. You also learned that this computation is sufficiently computationally expensive that would make it prohibitively expensive if we needed to evaluate it million or so times. The need to do so arises in statistical analyses when we try to find the best combination of $M$, $\\Omega_{\\rm m0}$, $\\Omega_\\Lambda$ that describe supernovae measurements or when we need to sample the range of these parameters  MCMC sampling that we will discuss next. \n",
    "\n",
    "This motivates constructing accurate approximations for $d_L(z,H_0,\\Omega_{\\rm m0},\\Omega_\\Lambda)$ using methods that we've been discussing in the last couple of classes (interpolation or regression). $d_L$ is a function of 4 parameters, but we do not need to construct approximation as a function of the Hubble constant $H_0$. This is because $d_L$ is proportional to $c/H_0$ and this is the only place where $H_0$ appears in its expression. Thus, if we tabulate $\\tilde{d}_L(z,\\Omega_{\\rm m0},\\Omega_\\Lambda)=d_L/(c/H_0)$, we can always then compute the actual value of the luminosity distance $d_L=c/H_0\\,\\tilde{d}_L(z,\\Omega_{\\rm m0}, \\Omega_\\Lambda)$. \n",
    "\n",
    "\n",
    "**Goal of the exercise.** The goal of this exercise is for you to find an optimal approximation of $\\tilde{d}_L$ (i.e. $d_L$ without $c/H_0$ factor) as a function of $\\Omega_{\\rm m0}$ and $\\Omega_\\Lambda$ (that is approximation should be two-dimensional, not two separate 1d approximations as a function of $\\Omega_{\\rm m0}$ and $\\Omega_\\Lambda$) for a given single value of $z$. \n",
    "\n",
    "\"Optimal\" here means that provides target accuracy of the approximation with the smallest training set of tabulated function values. Suppose our target fractional accuracy for $\\tilde{d}_L$ is $<10^{-4}$. Experiment with 2D polynomial and 2D piecewise spline interpolation for $\\tilde{d}_L$ with different number of training points using codes provided below and examples from the notebook [08_multid_optimization_class](https://drive.google.com/file/d/1-ptIvIvbRqtObk8x09ausJanXcqL8pJ0/view?usp=sharing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd85e3b7",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from astropy.cosmology import LambdaCDM\n",
    "import astropy.units as u\n",
    "\n",
    "def d_l_tilde_astropy(z, H0, Om0, OmL, clight=2.99792e5):\n",
    "    '''\n",
    "    compute d_l_tilde using AstroPy d_L function\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    z - float, or numpy array, redshift\n",
    "    H0 - float, Hubble constant in km/s/Mpc\n",
    "    Om0, OmL - floats, dimensionless matter and dark energy densities\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "        d_L - float, or numpy array, rescaled by c/H0 in Mpc \n",
    "    '''\n",
    "    cosmo = LambdaCDM(H0=H0, Om0=Om0, Ode0=OmL)\n",
    "    \n",
    "    return cosmo.luminosity_distance(z=z) / u.Mpc / (clight/H0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b45926",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def get_dl_train_test(ntrain=15, ntest=100, z=1.0, H0=70., \n",
    "                      om0min=0., om0max = 1., omlmin=0., omlmax=1.):\n",
    "    '''\n",
    "    Generate a grid of training values of d_L for a given redshift z, H0, and range\n",
    "    of Om0 and OmL for specified number of training points and their spacing\n",
    "    \n",
    "    Parameters:\n",
    "        ntrain - int, number of training points\n",
    "        ntest - int, number of test points\n",
    "        z - float, redshift for which to compute d_L_tilde values\n",
    "        H0 - float, Hubble constant in km/s/Mpc\n",
    "        om0min, om0max - floats, range of Omega_m0 values for which to generate training and test values\n",
    "        omlmin, omlmax - floats, range of Omega_Lambda values \n",
    "                \n",
    "    Returns:\n",
    "        om0tr, omltr - 1d numpy arrays of floats, training points\n",
    "        om0t, omlt   - 1d numpy arrays of floats, test points \n",
    "        dl_train, dl_test - 2d arrays of training and test values of d_L_tilde\n",
    "    '''\n",
    "    om0tr = np.linspace(om0min, om0max, ntrain)\n",
    "    omltr = np.linspace(omlmin, omlmax, ntrain)\n",
    "        \n",
    "    dl_train = np.zeros((ntrain, ntrain)) # initialize 2D numpy array for 2D grid of d_L values     \n",
    "    # Now cycle through Om0 and OmL values, compute d_L and fill the dlgrid array with values\n",
    "    for i, omd in enumerate(om0tr):\n",
    "        for j, omld in enumerate(omltr):\n",
    "                dl_train[i,j] = d_l_tilde_astropy(z, H0, omd, omld)\n",
    "\n",
    "    # test points             \n",
    "    om0t = np.linspace(om0min, om0max, ntest)\n",
    "    omlt = np.linspace(omlmin, omlmax, ntest)\n",
    "\n",
    "    dl_test = np.zeros((ntest, ntest)) # initialize 2D numpy array for 2D grid of d_L values \n",
    "    # Now cycle through Om0 and OmL values, compute d_L and fill the dlgrid array with values\n",
    "    for i, omd in enumerate(om0t):\n",
    "        for j, omld in enumerate(omlt):\n",
    "                dl_test[i,j] = d_l_tilde_astropy(z, H0, omd, omld)\n",
    "\n",
    "    return om0tr, omltr, om0t, omlt, dl_train, dl_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2255879d",
   "metadata": {},
   "source": [
    "**Task 1a. (4 points)**  Use functions above that generate 2D grids of d_L_tilde values. Try different numbers of training points along 1 dimension for the 2d spline approximation for $\\tilde{d}_L$ for the ranges $\\Omega_{\\rm m0}=[0,1]$ and $\\Omega_{\\Lambda}=[0,1]$ and  find the minimal number of training points for which we can ensure the fractional error of $\\tilde{d}_L$ $<10^{-4}$  for the entire range of $z\\in [0,2]$. \n",
    "\n",
    "You should \n",
    "\n",
    "* Report the minimal number of training points that you find. \n",
    "\n",
    "* Present a calculation or a plot that demonstrates that fractional error is smaller than $10^{-4}$ for the entire range of  $z\\in [0,2]$.\n",
    "\n",
    "**Note:** There are several different SciPy routines that can be used for this.  I recommend using function <tt>scipy.interpolate.RectBivariateSpline(x, y, z, s=0, kx=3, ky=3)</tt>, where $z$ is the array of function values tabulated at training points in vectors $x$ and $y$, $s=0$ indicates interpolation (no smoothing), parameters <tt>kx=3, ky=3</tt> specify that cubic splines should be used in $x$ and $y$ variables. Example of using this function is shown below (you can read about other available options and see examples of how they are used <a href=\"https://mmas.github.io/interpolation-scipy\">here</a>). Examples of how this function is used to construct 2D spline approximation is available in [08_multid_optimization_class](https://drive.google.com/file/d/1-ptIvIvbRqtObk8x09ausJanXcqL8pJ0/view?usp=sharing) notebook. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d94aecd",
   "metadata": {},
   "source": [
    "**Task 1b (6 points).** Using functions <tt>polyfit2d</tt> and <tt>poly2d</tt> below construct 2D polynomial approximations of $\\tilde{d}_L(z,\\Omega_{\\rm m0}, \\Omega_\\Lambda)$ for a given input single value of redshift $z$ and for ranges of the $\\Omega_{\\rm m0}$ and $\\Omega_\\Lambda)$ parameters of $\\Omega_{\\rm m0}\\in [0,1]$ and $\\Omega_\\Lambda\\in[0,1]$. \n",
    "\n",
    "Try different number of training points and polynomial order and try to find the minimal number and order that ensures the target fractional accuracy of $<10^{-4}$ for any $z$ in the interval $z\\in [0,2]$. \n",
    "\n",
    "You should:\n",
    "\n",
    "* Report the minimal number of training points that you find. \n",
    "\n",
    "* Present a calculation or a plot that demonstrates that fractional error is smaller than $10^{-4}$ for the entire range of  $z\\in [0,2]$.\n",
    "\n",
    "\n",
    "Based on the results of 1a and 1b, state your conclusions about the optimal method for approximating $\\tilde{d}_L(z,\\Omega_{\\rm m0}, \\Omega_\\Lambda)$ with this target accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "dec1edf2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def polyfit2d(xtr, ytr, ftr, order=None):\n",
    "    '''\n",
    "    Parameters:\n",
    "        xtr, ytr - 1d numpy vectors with training points of x and y\n",
    "        ftr - function values at xtr, ytr values\n",
    "        order - int, order of the polynomial\n",
    "        \n",
    "    Returns:\n",
    "        coefficients of the 2D polynomial\n",
    "    '''\n",
    "    # generate 2d coordinates on a rectangular grid\n",
    "    x, y = np.meshgrid(xtr, ytr)\n",
    "    # coefficient array, up to x^kx, y^ky\n",
    "    coeffs = np.ones((order+1, order+1))\n",
    "    # array that will contain polynomial term values \n",
    "    V = np.zeros((coeffs.size, x.size))\n",
    "\n",
    "    # construct the 2D matrix of values for each polynomial term i, j\n",
    "    for index, (j, i) in enumerate(np.ndindex(coeffs.shape)):\n",
    "        # do not include powers greater than order\n",
    "        if order is not None and i + j > order:\n",
    "            arr = np.zeros_like(x)\n",
    "        else:\n",
    "            arr = x**i * y**j # coeffs[i, j] * \n",
    "        V[index] = arr.flatten() \n",
    "        \n",
    "    # solve for the polynomial coefficients using least squares approximation of ftr values \n",
    "    return np.linalg.lstsq(V.T, np.ravel(ftr), rcond=None)[0]\n",
    "\n",
    "def poly2d(xtest, ytest, a):\n",
    "    '''\n",
    "    Compute values of the 2D polynomial given the coefficients in 1d array a \n",
    "    at points given by 2d arrays xtest and ytest (generated using meshgrid)\n",
    "    '''\n",
    "    order1 = np.rint(a.size**0.5).astype(int)\n",
    "    return np.polynomial.polynomial.polyval2d(xtest, ytest, a.reshape((order1,order1)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903195f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e811c78",
   "metadata": {},
   "source": [
    "## <font color='blue'>Exercise 2: implementing and testing  Differential Evolution algorithm for minimization (25 points + 5 extra-credit points)</font>\n",
    "\n",
    "**Background.** Minimization in many dimensions is generally a complicated task. However, a class of <a href=\"https://en.wikipedia.org/wiki/Differential_evolution\">Differential Evolution</a> (DE) algorithms developed from the initial ideas of R. Storn and K. Price in 1997 (<a href=\"https://link.springer.com/article/10.1023%2FA%3A1008202821328\">Storn & Price 1997</a>), are relatively simple to implement, work in arbitrary number of dimensions, do not require function derivatives, allow imposing bounds on the domain, and are quite efficient in minimizing multi-dimensional functions.\n",
    "\n",
    "### <font color='blue'>What you are learning in this exercise:</font>\n",
    "\n",
    "* how to implement a general multi-dimensional minimization DE algorithm\n",
    "* how to find minimum of a function in practice. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac70894",
   "metadata": {},
   "source": [
    "The simplest version of the differential evolution algorithm described in detail in the notebook [08_optimization](https://drive.google.com/file/d/1oq838Jla7r6upwYf1uE7Oa6ctua0gIqU/view?usp=sharing),  can be presented as the following pseudo-code:  \n",
    "\n",
    "    npop = np.size(x0)[0] # the number of population members\n",
    "    fnow = func(xnow)\n",
    "    xnow = np.copy(x0)\n",
    "    xnext = np.zeros_like(xnow)\n",
    "    ....\n",
    "    while some convergence criterion is not met: \n",
    "        # xnow is a vector of coordinate vectors of the current population\n",
    "        # xnext is a vector of coordinate vector of the next gen population\n",
    "        for i in range(npop):\n",
    "            # generate random unique indices  ir1, ir2, ir3 \n",
    "            # where all indices are not equal to each other and not equal to i\n",
    "            # s can be a constant for large npop, but it's more safe to make it a\n",
    "            # random number drawn from uniform distribution in the range [smin,1]\n",
    "            xtry = xnow[ir3] + s * (xnow[ir1] - xnor[ir2])\n",
    "            if func(xtry) <= fnow[i]:\n",
    "                xnext[i] = xtry\n",
    "            else:\n",
    "                xnext[i] = xnow[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657b2c7d",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b8403c",
   "metadata": {},
   "source": [
    "**Task 2a. (20 points)** Use pseudo-code of the DE algorithm above to implement DE minimization function with the following interface (15 points):\n",
    "\n",
    "    def minimize_de(func, x0, atol=1.e-6, s=0.1, bounds=None):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        ------------\n",
    "        func - Python function object\n",
    "               function to minimize, should expect x0 as a parameter vector\n",
    "        x0   - vector of real numbers of shape (npop, nd), \n",
    "                where npop is population size and nd is the number of func parameters\n",
    "        atol - float\n",
    "                absolute tolerance threshold for change of population member positions\n",
    "        s    - float \n",
    "               s parameter for scaling steps, the step size will be dwarf from uniform distribution between s and 1\n",
    "        bounds - array of tuples \n",
    "                bounds for the minimization exploration; define the region in which to search for the minimum\n",
    "        \"\"\"\n",
    "                \n",
    "\n",
    "***Note:*** guard against for the cases when the small number of population members is used when population does not move at a given mutation stage, so that this does not result in premature stopping of the algorithm. \n",
    "\n",
    "***Note:*** Try to \"vectorize\" as much of the algorithm as possible. This code can be fully vectorized with only one loop for the mutations of the population. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9098006e",
   "metadata": {},
   "source": [
    "***Note:*** Assuming that we are searching for a minimum within some rectangular domain defined by the minimum and maximum values along each coordinate axis: $\\mathbf{x}_{\\rm min}$ and $\\mathbf{x}_{\\rm max}$, we can initialize the population members as \n",
    "\n",
    "$$\\mathbf{x}_0 = \\mathbf{x}_{\\rm min} + (\\mathbf{x}_{\\rm max}-\\mathbf{x}_{\\rm min}) \\cdot\\mathrm{rand}(0,1),$$\n",
    "\n",
    "where $\\mathrm{rand}(0,1)$ is a random number uniformly distributed from 0 to 1, generated using <tt>np.random.uniform</tt>.  \n",
    "\n",
    "***Note:*** the algorithm requires selection of 3 random indices of members, excluding the current member that is being mutated. As always, there are multiple ways of doing this in Python. Below is one example of how this can be done using NumPy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76b0ba14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3 6\n"
     ]
    }
   ],
   "source": [
    "npop = 10 # number of population members \n",
    "inds = np.arange(npop) # create a list of indices from 0 to npop-1\n",
    "inds = np.delete(inds,7) # remove specific index 7 from inds\n",
    "np.random.shuffle(inds) # shuffle indices randomly\n",
    "print(inds[0], inds[1], inds[2]) # print the first 3 of the shuffled indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68871f9c",
   "metadata": {},
   "source": [
    "***Таск 2b (5 points).*** Test your implementation using Rosenbrock function implemented below in 2- and 5-dimensions. Try different number of population members and $s$ values and choices for how $s$ is chosen and examine how results change and for what number of population members the algorithm returns correct minimum value reliably ($[1,1]$ in 2D and $[1, 1, 1, 1, 1]$ in 5D). \n",
    "\n",
    "* Present a brief discussion of how large population should be in 2D and 5D to get correct minimum reliably. \n",
    "\n",
    "* Present a brief discussion of how choices of $s$ affect results \n",
    "\n",
    "* Demonstrate that your function returns values within the specified atol value reliably in 5D. \n",
    "\n",
    "* Compare results of your function to results of the <tt>scipy.optimize.differential_evolution</tt>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1205,
   "id": "7c42a104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosenbrock(x):\n",
    "    \"\"\"The Rosenbrock \"banana\" function\n",
    "    x is a vector of points in 2 or more dimensional space\n",
    "    \"\"\"\n",
    "    return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65651302",
   "metadata": {},
   "source": [
    "## <font color='blue'> Exercise 3: implementing cross-over stage of the DE algorithm (extra-credit 10 points).</font>\n",
    "\n",
    "\n",
    "Implement the modification of DE with the cross-over stage of the algorithm described below  and test your implementation using the Rosenbrock pdf in 2- and 5 dimensions.  (7 points)\n",
    "\n",
    "Discuss what difference you can notice in the performance of the algorithm with the crossover stage compared to the simplest form in exercise 2 (3 points). \n",
    "\n",
    "\n",
    "**Cross-over stage of the DE algorithm**. One of the modifications to this basic algorithm is introduction of the ***crossover stage*** so that the mutation and crossover stages together are as follows: \n",
    "\n",
    "* compute mutation vector $\\mathbf{x}^\\prime_i=\\mathbf{x}_{{\\rm now}, r_3} + s\\,(\\mathbf{x}_{{\\rm now}, r_2}-\\mathbf{x}_{{\\rm now}, r_1})$, as before, where vector $\\mathbf{x}^\\prime_i$ has components $\\mathbf{x}^\\prime_i=[x^{\\prime}_{0i}, x^{\\prime}_{1i}, \\ldots, x^{\\prime}_{(D-1)i}]$, and $D$ is the number of parameters of the minimized function (i.e., dimensionality of the problem). \n",
    "\n",
    "* \"***crossover stage***\": form the trial vector $\\mathbf{x}^{\\prime\\prime}_i=[x^{\\prime\\prime}_{0i}, x^{\\prime\\prime}_{1i}, \\ldots, x^{\\prime\\prime}_{(D-1)i}]$, where \n",
    "\n",
    "\\begin{equation}\n",
    "x^{\\prime\\prime}_{ji} = \n",
    "\\begin{cases}\n",
    "x^{\\prime}_{ji}, \\ {\\rm if\\ }r_j\\leq \\mathrm{cr\\ or\\ } j= \\mathrm{ir}_i,\\\\\n",
    "x_{{\\rm now},ji}, \\ {\\rm otherwise\\ }\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "and $r_j$ is the random floating point number uniformly distributed in the interval $[0,1]$ that is generated for the index $j$, and $\\mathrm{ir}_i$ is the random integer uniformly distributed in the range $[0, D-1]$ generated for index $i$, which ensures that $\\mathbf{x}^{\\prime\\prime}_i$ gets at least one element from $\\mathbf{x}^\\prime_i$. The crossover parameter $\\mathrm{cr}\\in [0,1]$ is a constant set by user. \n",
    "\n",
    "* *Selection stage:* if $f(\\mathbf{x}^{\\prime\\prime}_i)\\leq f(\\mathbf{x}_{{\\rm now},i})$, then $\\mathbf{x}_{{\\rm next},i}=\\mathbf{x}^{\\prime\\prime}_i$, else $\\mathbf{x}_{{\\rm next},i}=\\mathbf{x}_{{\\rm now},i}$ (no mutation). \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
